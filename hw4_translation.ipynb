{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDxtMC2g66gQ"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vj2CXov7JJqq"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcKp4bZiJwut"
      },
      "outputs": [],
      "source": [
        "%cd 'YOUR_DRIVE'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UHKo6dP6eEO6"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import random\n",
        "from pathlib import Path\n",
        "import sys\n",
        "sys.path.insert(0,str(Path().absolute().joinpath(\"data\")))\n",
        "\n",
        "from data import prepareData\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer, TransformerDecoder, TransformerDecoderLayer\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "########### import yours ###########\n",
        "\n",
        "####################################\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# TRAIN_RATIO: train dataset ratio, should be a float in (0, 0.8]\n",
        "# (0.8-TRAIN_RATIO) will be used for valid dataset\n",
        "TRAIN_RATIO = 0.6 "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Util"
      ],
      "metadata": {
        "id": "Kz2VM-9MIyKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Do NOT Modify** code blocks in this section"
      ],
      "metadata": {
        "id": "8qCY42PE0kRj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOnSsL1EeG85"
      },
      "outputs": [],
      "source": [
        "SEED = 1234\n",
        "\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "random.seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, loss_fn, clip):\n",
        "    \n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "\n",
        "        src = batch[0].to(device)\n",
        "        trg = batch[1].to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(src, trg)\n",
        "        loss = loss_fn(output, trg)\n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "metadata": {
        "id": "UHo7XkIGIz2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, loss_fn):\n",
        "    \n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src = batch[0].to(device)\n",
        "            trg = batch[1].to(device)\n",
        "\n",
        "            output = model(src, trg)\n",
        "\n",
        "            loss = loss_fn(output, trg)\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "metadata": {
        "id": "l2-jeXr-I1yP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PgCsIyawXoN"
      },
      "source": [
        "## Dataset & Dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Do NOT Modify** code blocks in this section"
      ],
      "metadata": {
        "id": "40ZOR80S0wet"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 10\n",
        "VALID_RATIO = 0.8-TRAIN_RATIO\n",
        "\n",
        "SOS_token = 0\n",
        "EOS_token = 1"
      ],
      "metadata": {
        "id": "jwwJGiyETHsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fePBsU2GKoaI",
        "outputId": "16074007-6d7b-441c-af2b-099a9bb11dc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 135842 sentence pairs\n",
            "Trimmed to 10599 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "fra 4345\n",
            "eng 2803\n",
            "data example\n",
            "['tu me fais de l ombre .', 'you re blocking my light .']\n"
          ]
        }
      ],
      "source": [
        "class TranslateDataset(Dataset):\n",
        "    def __init__(self, max_length=10, fra2eng=True):\n",
        "        self.input_lang, self.output_lang, self.pairs = prepareData('eng', 'fra', max_length=max_length, reverse=fra2eng)\n",
        "        self.max_length=max_length\n",
        "\n",
        "        self.input_lang.addWord('PAD')\n",
        "        self.output_lang.addWord('PAD')\n",
        "        self.input_lang_pad = self.input_lang.word2index['PAD']\n",
        "        self.output_lang_pad = self.output_lang.word2index['PAD']\n",
        "        \n",
        "        print(\"data example\")\n",
        "        print(random.choice(self.pairs))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pair = self.pairs[idx]\n",
        "        x, y = self._tensorsFromPair(pair)\n",
        "        return x, y\n",
        "\n",
        "    def _tensorFromSentence(self, lang, sentence):\n",
        "        indexes = [lang.word2index[word] for word in sentence.split(' ')]\n",
        "        indexes.append(EOS_token)\n",
        "        return torch.tensor(indexes, dtype=torch.long).view(-1, 1)\n",
        "\n",
        "    def _tensorsFromPair(self, pair):\n",
        "        input_tensor = self._tensorFromSentence(self.input_lang, pair[0])\n",
        "        target_tensor = self._tensorFromSentence(self.output_lang, pair[1])\n",
        "        return (input_tensor, target_tensor)\n",
        "    \n",
        "    def collate_fn(self, data):\n",
        "        x_batch = []; y_batch = []\n",
        "        \n",
        "        for x, y in data:\n",
        "            if x.shape[0] < self.max_length-1:\n",
        "                x = torch.cat([x, self.input_lang_pad*torch.ones((self.max_length-1 - x.shape[0], 1), dtype=x.dtype)])\n",
        "            elif x.shape[0] > self.max_length-1:\n",
        "                x = x[:self.max_length-1]\n",
        "            if y.shape[0] < self.max_length-1:\n",
        "                y = torch.cat([y, self.output_lang_pad*torch.ones((self.max_length-1 - y.shape[0], 1), dtype=y.dtype)])\n",
        "            elif y.shape[0] > self.max_length-1:\n",
        "                y = y[:self.max_length-1]\n",
        "\n",
        "            x_batch.append(torch.cat([torch.tensor([SOS_token]), x.squeeze(1)]))\n",
        "            y_batch.append(torch.cat([torch.tensor([SOS_token]), y.squeeze(1)]))\n",
        "        \n",
        "        return torch.stack(x_batch), torch.stack(y_batch)\n",
        "\n",
        "dataset = TranslateDataset(max_length=MAX_LENGTH)\n",
        "\n",
        "train_size = int(len(dataset)*TRAIN_RATIO)\n",
        "valid_size = int(len(dataset)*VALID_RATIO)\n",
        "train_data, valid_data, test_data = random_split(dataset, [train_size, valid_size, len(dataset)-(train_size+valid_size)],)\n",
        "\n",
        "train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, collate_fn=dataset.collate_fn, shuffle=True)\n",
        "valid_dataloader = DataLoader(valid_data, batch_size=BATCH_SIZE, collate_fn=dataset.collate_fn, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE, collate_fn=dataset.collate_fn, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TqutY58tG-h"
      },
      "source": [
        "# 1. Seq2Seq model with Attention Mechanism"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5xyf2mHuhmX"
      },
      "source": [
        "## Implement LSTM Seq2Seq Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMEncoder(nn.Module):\n",
        "    \n",
        "    def __init__(self, in_dim, emb_dim, hid_dim):\n",
        "        super(LSTMEncoder, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(in_dim, emb_dim)\n",
        "        self.lstm = nn.LSTM(input_size=emb_dim, hidden_size=hid_dim, num_layers=1, batch_first=True)\n",
        "\n",
        "\n",
        "    def forward(self, input, hidden, cell):\n",
        "        '''\n",
        "        Q2 - (a)\n",
        "        Implement forward method of LSTM Encoder Module\n",
        "\n",
        "        INPUT\n",
        "        - input: input sentence, (B, max_len)\n",
        "        - hidden: initialized hidden state, (1, B, hid_dim)\n",
        "        - cell: initialized cell state, (1, B, hid_dim)\n",
        "\n",
        "        OUTPUT\n",
        "        What to be returned depends on your implementation of LSTMSeq2Seq. (Q2 - (b))\n",
        "        Feel free to return outputs you need.\n",
        "        some examples below\n",
        "        - hidden states of encoder\n",
        "\n",
        "        '''\n",
        "        ################### YOUR CODE ###################\n",
        "        \n",
        "        return\n",
        "        #################################################"
      ],
      "metadata": {
        "id": "1MM6lL95JcDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttnLSTMDecoder(nn.Module):\n",
        "\n",
        "    def __init__(self, emb_dim, hid_dim, out_dim, dropout, enc_hiddens=None):\n",
        "        super(AttnLSTMDecoder, self).__init__()\n",
        "        \n",
        "        self.t = 0 # (t)th token decoder\n",
        "        self.enc_hiddens = enc_hiddens # encoder output\n",
        "        self.dropout = dropout\n",
        "        \n",
        "        self.embedding = nn.Embedding(out_dim, emb_dim)\n",
        "        self.lstm = nn.LSTM(emb_dim + hid_dim, hid_dim, batch_first=True)\n",
        "        self.classifier = nn.Linear(hid_dim, out_dim)\n",
        "\n",
        "\n",
        "    def forward(self, input, hidden, cell):\n",
        "        \n",
        "        '''\n",
        "        Q2 - (a)\n",
        "        Implement forward method of LSTM Decoder Module with dot-product attention\n",
        "\n",
        "        INPUT\n",
        "        - input: input sentence (B, 1)\n",
        "        - hidden: previous hidden state (B, hid_dim)\n",
        "        - cell: previous cell state (1, B, hid_dim)\n",
        "\n",
        "        OUTPUT\n",
        "        What to be returned depends on your implementation of LSTMSeq2Seq. (Q2 - (b))\n",
        "        Feel free to return outputs you need.\n",
        "        Some examples below\n",
        "        - predicted token embedding (B, n_words of target language), (B, emb_dim), etc.\n",
        "        - current hidden state\n",
        "        - current cell state\n",
        "        '''\n",
        "\n",
        "        ################### YOUR CODE ###################\n",
        "\n",
        "        query = hidden # set query to calculate attention\n",
        "\n",
        "        self.t += 1 # update time for each forward\n",
        "\n",
        "        return\n",
        "        #################################################\n"
      ],
      "metadata": {
        "id": "VPQnZdz5KKnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMSeq2Seq(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim, emb_dim, hid_dim, device, dropout):\n",
        "        super(LSTMSeq2Seq, self).__init__()\n",
        "\n",
        "        self.in_dim = in_dim\n",
        "        self.out_dim = out_dim\n",
        "        self.emb_dim = emb_dim\n",
        "        self.hid_dim = hid_dim\n",
        "        self.device = device\n",
        "        self.dropout = dropout\n",
        "        \n",
        "        self.encoder = LSTMEncoder(in_dim, emb_dim, hid_dim)\n",
        "        self.decoder = AttnLSTMDecoder(emb_dim, hid_dim, out_dim, dropout)\n",
        "        \n",
        "    def forward(self, src, trg):\n",
        "        '''\n",
        "        Q2 - (b)\n",
        "        Implement forward method of LSTM Seq2Seq Module\n",
        "        (Decoder module should attend encoder's outputs using dot product.)\n",
        "        \n",
        "        INPUT\n",
        "        - src: source language batched data (B, max_len)\n",
        "        - trg: target language batched data (B, max_len)\n",
        "\n",
        "        OUTPUT\n",
        "        - output of token prediction (B, out_dim, max_len)\n",
        "        '''\n",
        "        batch_size, mx_len = src.shape\n",
        "        ################### YOUR CODE ###################\n",
        "\n",
        "        # Encoder (start from zero-hidden & zero-cell states)\n",
        "\n",
        "        \n",
        "        # Decoder\n",
        "        self.decoder.enc_hiddens = None # set encoder's hidden states\n",
        "        outputs = torch.zeros(mx_len, batch_size, dataset.output_lang.n_words).to(self.device) # to store each decoder's output\n",
        "        \n",
        "        for t in range(1, mx_len): # for each t'th token, get decoder outputs\n",
        "            continue\n",
        "        \n",
        "        \n",
        "        self.decoder.t=0 # after for loop, reset decoder's time to evaluate properly\n",
        "\n",
        "\n",
        "        return \n",
        "        ################### YOUR CODE ###################"
      ],
      "metadata": {
        "id": "zJsJ3p2NLD6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cu3WP3mYw3NV"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Q2 - (c)\n",
        "Train your Seq2Seq model and plot losses and perplexities.\n",
        "Upon successful training, the test perplexity should be less than 5.\n",
        "You may use visualization libraries for plotting and modify training options such as hyperparameters and optimizer.\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "B4YKhRe9d9qC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "687c2cf4-1c0d-4fbe-bd3c-b42dcedd768f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nQ2 - (c)\\nTrain your Seq2Seq model and plot losses and perplexities.\\nUpon successful training, the test perplexity should be less than 5.\\nYou may use visualization libraries for plotting and modify training options such as hyperparameters and optimizer.\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QQgN03XecUV"
      },
      "outputs": [],
      "source": [
        "in_dim = dataset.input_lang.n_words\n",
        "out_dim = dataset.output_lang.n_words\n",
        "hid_dim = 256\n",
        "emb_dim = 256\n",
        "dropout = 0.1\n",
        "learning_rate=1e-2\n",
        "N_EPOCHS = 100\n",
        "valid_every=5\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = LSTMSeq2Seq(in_dim, out_dim, emb_dim, hid_dim, device, dropout).to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "loss_fn = nn.NLLLoss(ignore_index = dataset.output_lang_pad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JbSR6BZKf-6L"
      },
      "outputs": [],
      "source": [
        "# Train your model\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    train_loss = train(model, train_dataloader, optimizer, loss_fn, 1)\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02}')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    \n",
        "    if epoch%valid_every==0:\n",
        "        print(\"==========================\")\n",
        "        valid_loss = evaluate(model, valid_dataloader, loss_fn)\n",
        "\n",
        "        if valid_loss < best_valid_loss:\n",
        "            best_valid_loss = valid_loss\n",
        "            model.decoder.t=0\n",
        "            torch.save(model.state_dict(), 'lstm-attn-model.pt')\n",
        "\n",
        "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your model\n",
        "\n",
        "loaded_model = LSTMSeq2Seq(in_dim, out_dim, emb_dim, hid_dim, device, dropout).to(device)\n",
        "loaded_model.load_state_dict(torch.load('lstm-attn-model.pt'))\n",
        "\n",
        "test_loss = evaluate(loaded_model, test_dataloader, loss_fn)\n",
        "print(f'\\t Test. Loss: {valid_loss:.3f} |  Test. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "metadata": {
        "id": "hBXKAKZo2lSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [Bonus] Implement GRU Seq2Seq Model"
      ],
      "metadata": {
        "id": "FD1SYbuKOKGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Q2 - (d)\n",
        "Change the modules(encoder, decoder) in Seq2Seq model to GRU, and repeat (a)~(c).\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "Ei1fgjRveS4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GRUEncoder(nn.Module):\n",
        "    \n",
        "    def __init__(self, in_dim, emb_dim, hid_dim):\n",
        "        super(GRUEncoder, self).__init__()\n",
        "        ################### YOUR CODE ###################\n",
        "\n",
        "        #################################################\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "\n",
        "        ################### YOUR CODE ###################\n",
        "\n",
        "        return\n",
        "        #################################################"
      ],
      "metadata": {
        "id": "2U9A9kh3OSWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttnGRUDecoder(nn.Module):\n",
        "\n",
        "    def __init__(self, emb_dim, hid_dim, out_dim, dropout, enc_hiddens=None):\n",
        "        super(AttnGRUDecoder, self).__init__()\n",
        "        \n",
        "        ################### YOUR CODE ###################\n",
        "\n",
        "        #################################################\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "\n",
        "        ################### YOUR CODE ###################\n",
        "\n",
        "        return \n",
        "        #################################################\n"
      ],
      "metadata": {
        "id": "9-IRYjI6O0xb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GRUSeq2Seq(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim, emb_dim, hid_dim, device, dropout):\n",
        "        super(GRUSeq2Seq, self).__init__()\n",
        "\n",
        "        self.in_dim = in_dim\n",
        "        self.out_dim = out_dim\n",
        "        self.emb_dim = emb_dim\n",
        "        self.hid_dim = hid_dim\n",
        "        self.device = device\n",
        "        self.dropout = dropout\n",
        "        \n",
        "        self.encoder = GRUEncoder(in_dim, emb_dim, hid_dim)\n",
        "        self.decoder = AttnGRUDecoder(emb_dim, hid_dim, out_dim, dropout)\n",
        "        \n",
        "    def forward(self, src, trg):\n",
        "        \n",
        "        batch_size, mx_len = src.shape\n",
        "        ################### YOUR CODE ###################\n",
        "        \n",
        "        # Encoder\n",
        "        \n",
        "        # Decoder\n",
        "        \n",
        "        for t in range(1, mx_len):\n",
        "            continue\n",
        "        \n",
        "        return\n",
        "        #################################################"
      ],
      "metadata": {
        "id": "BOOj4_hhP83d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "gru_model = GRUSeq2Seq(in_dim, out_dim, emb_dim, hid_dim, device, dropout).to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "loss_fn = nn.NLLLoss(ignore_index = dataset.output_lang_pad)\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    train_loss = train(model, train_dataloader, optimizer, loss_fn, 1)\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02}')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    \n",
        "    if epoch%valid_every==0:\n",
        "        print(\"==========================\")\n",
        "        valid_loss = evaluate(model, valid_dataloader, loss_fn)\n",
        "\n",
        "        if valid_loss < best_valid_loss:\n",
        "            best_valid_loss = valid_loss\n",
        "            model.decoder.t=0\n",
        "            torch.save(model.state_dict(), 'gru-attn-model.pt')\n",
        "\n",
        "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "metadata": {
        "id": "usq_ohj4Qqf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = GRUSeq2Seq(in_dim, out_dim, emb_dim, hid_dim, device, dropout).to(device)\n",
        "model.load_state_dict(torch.load('gru-attn-model.pt'))\n",
        "\n",
        "test_loss = evaluate(model, test_dataloader, loss_fn)\n",
        "print(f'\\t Test. Loss: {valid_loss:.3f} |  Test. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "metadata": {
        "id": "WrFYlXfiRCSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Seq2Seq model with Transformer"
      ],
      "metadata": {
        "id": "qAZdJqTJXVcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implement Transformer Seq2Seq Model"
      ],
      "metadata": {
        "id": "t07UOwbpH7CZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, hid_dim, n_layers, n_heads, ff_dim, dropout, device, max_length = MAX_LENGTH):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hid_dim = hid_dim\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
        "        \n",
        "        encoder_layer = TransformerEncoderLayer(hid_dim, n_heads, ff_dim, dropout, batch_first=True)\n",
        "        self.encoder = TransformerEncoder(encoder_layer, n_layers)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.scale = torch.sqrt(torch.tensor([hid_dim], device = device, dtype=torch.float32))\n",
        "        \n",
        "    def forward(self, src, pos_emb, src_mask):\n",
        "        '''\n",
        "        Q3 - (c)\n",
        "        Implement forward method of TransEncoder Module\n",
        "        (Use torch.nn.TransformerEncoder, torch.nn.TransformerEncoderLayer)\n",
        "        \n",
        "        INPUT\n",
        "        - src: source language batched data (B, max_len)\n",
        "        - pos_emb: positional embedding (max_len, hid_dim)\n",
        "        - src_mask: padding mask tensor for source sentences (B, max_len)\n",
        "\n",
        "        OUTPUT\n",
        "        What to be returned depends on your implementation of TransSeq2Seq.\n",
        "        Feel free to return outputs you need.\n",
        "        Some examples below,\n",
        "\n",
        "        - encoder output (B, max_len, hid_dim)\n",
        "        '''\n",
        "        batch_size, src_len = src.shape\n",
        "        #################### YOUR CODE ####################\n",
        "\n",
        "        \n",
        "        return None\n",
        "        ###################################################"
      ],
      "metadata": {
        "id": "Cvv3bN0qXX1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransDecoder(nn.Module):\n",
        "    def __init__(self, out_dim, hid_dim, n_layers, n_heads, ff_dim, dropout, device, max_length = MAX_LENGTH):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.hid_dim = hid_dim\n",
        "        self.max_length = max_length\n",
        "        \n",
        "        self.tok_embedding = nn.Embedding(out_dim, hid_dim)\n",
        "        \n",
        "        decoder_layer = TransformerDecoderLayer(hid_dim, n_heads, ff_dim, dropout, batch_first=True)\n",
        "        self.decoder = TransformerDecoder(decoder_layer, n_layers)\n",
        "        \n",
        "        self.fc_out = nn.Linear(hid_dim, out_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.tensor([hid_dim], device = device, dtype=torch.float32))\n",
        "        \n",
        "    def forward(self, trg, pos_emb, enc_src, trg_mask, trg_sub_mask, src_mask):\n",
        "        '''\n",
        "        Q3 - (c)\n",
        "        Implement forward method of TransDecoder Module\n",
        "        (Use torch.nn.TransformerDecoder, torch.nn.TransformerDecoderLayer)\n",
        "        \n",
        "        INPUT\n",
        "        - trg: target language batched data (B, max_len)\n",
        "        - pos_emb: positional embedding (max_len, hid_dim)\n",
        "        - enc_src: encoder outputs (B, max_len, hid_dim)\n",
        "        - trg_mask: padding mask tensor for target sentences (B, max_len)\n",
        "        - trg_sub_mask: subsequent mask for target sentences (max_len, max_len)\n",
        "        - src_mask: padding mask tensor for source sentences (B, max_len)\n",
        "\n",
        "        OUTPUT\n",
        "        What to be returned depends on your implementation of TransSeq2Seq.\n",
        "        Feel free to return outputs you need.\n",
        "        Some examples below,\n",
        "\n",
        "        - decoder output (B, max_len, out_dim)\n",
        "        '''\n",
        "        batch_size, trg_len = trg.shape\n",
        "\n",
        "        #################### YOUR CODE ####################\n",
        "        \n",
        "        return None\n",
        "        ###################################################"
      ],
      "metadata": {
        "id": "8mKifSxjIWKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransSeq2Seq(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim, hid_dim, ff_dim, n_layers, n_heads, dropout_p, device, max_length=MAX_LENGTH):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.device = device\n",
        "        self.hid_dim = hid_dim\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.encoder = TransEncoder(in_dim, hid_dim, n_layers[0], n_heads, ff_dim, dropout_p, device)\n",
        "        self.decoder = TransDecoder(out_dim, hid_dim, n_layers[1], n_heads, ff_dim, dropout_p, device)\n",
        "        \n",
        "    def make_src_mask(self, src):\n",
        "        '''\n",
        "        Q3 - (b)\n",
        "        Implement mask generating function\n",
        "\n",
        "        INPUT\n",
        "        - src: batched input sentences (B, max_len)\n",
        "\n",
        "        OUTPUT\n",
        "        - Boolean padding mask tensor (B, max_len)\n",
        "        '''\n",
        "        #################### YOUR CODE ####################\n",
        "        \n",
        "        return None\n",
        "        ###################################################\n",
        "\n",
        "    def make_trg_mask(self, trg):\n",
        "        '''\n",
        "        Q3 - (b)\n",
        "        Implement mask generating function\n",
        "\n",
        "        INPUT\n",
        "        - trg: batched target sentences (B, max_len)\n",
        "\n",
        "        OUTPUT\n",
        "        - A tuple of a padding mask tensor and a subsequent mask tensor ((B, max_len), (max_len, max_len))\n",
        "        '''\n",
        "        #################### YOUR CODE ####################\n",
        "\n",
        "        return None\n",
        "        ###################################################\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        '''\n",
        "        Q3 - (c)\n",
        "        Implement forward method of TransSeq2Seq Module\n",
        "        \n",
        "        INPUT\n",
        "        - src: source language batched data (B, max_len)\n",
        "        - trg: target language batched data (B, max_len)\n",
        "\n",
        "        OUTPUT\n",
        "        - decoder output (B, out_dim, max_dim)\n",
        "        \n",
        "        '''\n",
        "        #################### YOUR CODE ####################\n",
        "\n",
        "        return None\n",
        "        ###################################################\n",
        "    \n",
        "    \n",
        "    def get_pos_emb(self):\n",
        "        '''\n",
        "        Q3 - (a)\n",
        "        Implement absolute positional embedding\n",
        "\n",
        "        OUTPUT\n",
        "        - positional embedding tensor (max_len, hid_dim)\n",
        "        '''\n",
        "        #################### YOUR CODE ####################\n",
        "\n",
        "        return None\n",
        "        ###################################################"
      ],
      "metadata": {
        "id": "L5VFP1-3IXmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "KqnvbugEIJ-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Q3 - (d)\n",
        "Train your Seq2Seq model and plot losses and perplexities.\n",
        "Upon successful training, the test perplexity should be less than 2.\n",
        "You may use visualization libraries for plotting and modify training options such as hyperparameters and optimizer.\n",
        "\n",
        "Based on the results from lSTM(GRU)-based and transformer-based Seq2Seq models,\n",
        "briefly describe which approach is better and why.\n",
        "'''"
      ],
      "metadata": {
        "id": "s8XBEzSHaUdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "in_dim = dataset.input_lang.n_words\n",
        "out_dim = dataset.output_lang.n_words\n",
        "hid_dim = 256\n",
        "ff_dim = 1024\n",
        "n_enc_layers = 4\n",
        "n_dec_layers = 4\n",
        "n_layers = [n_enc_layers, n_dec_layers]\n",
        "n_heads = 8\n",
        "dropout = 0.1\n",
        "\n",
        "learning_rate=1e-2\n",
        "N_EPOCHS = 100\n",
        "valid_every=5\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = TransSeq2Seq(in_dim, out_dim, hid_dim, ff_dim, n_layers, n_heads, dropout, device).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "loss_fn = nn.CrossEntropyLoss(ignore_index = dataset.output_lang_pad)\n",
        "# print(model)"
      ],
      "metadata": {
        "id": "hdNx0Ol5ILbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train your model\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    train_loss = train(model, train_dataloader, optimizer, loss_fn, 1)\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02}')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    \n",
        "    if epoch%valid_every==0:\n",
        "        print(\"==========================\")\n",
        "        valid_loss = evaluate(model, valid_dataloader, loss_fn)\n",
        "\n",
        "        if valid_loss < best_valid_loss:\n",
        "            best_valid_loss = valid_loss\n",
        "            model.decoder.t=0\n",
        "            torch.save(model.state_dict(), 'transformer-model.pt')\n",
        "\n",
        "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "metadata": {
        "id": "aES3_sBTIgnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your model\n",
        "loaded_model = TransSeq2Seq(in_dim, out_dim, hid_dim, ff_dim, n_layers, n_heads, dropout, device).to(device)\n",
        "loaded_model.load_state_dict(torch.load('transformer-model.pt'))\n",
        "\n",
        "test_loss = evaluate(loaded_model, test_dataloader, loss_fn)\n",
        "print(f'\\t Test. Loss: {valid_loss:.3f} |  Test. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "metadata": {
        "id": "4M6sUc-aJKP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gCswrEKrLeiQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "EDxtMC2g66gQ",
        "Kz2VM-9MIyKe",
        "5PgCsIyawXoN",
        "cu3WP3mYw3NV",
        "FD1SYbuKOKGN",
        "qAZdJqTJXVcP",
        "t07UOwbpH7CZ",
        "KqnvbugEIJ-h"
      ],
      "name": "hw4_translation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}